group: parsinlu-multiple-choice
task: category_zs
dataset_path: PNLPhub/parsinlu-multiple-choice
dataset_name: null
output_type: greedy_until
use_prompt: "promptsource:category_zs"
# target_delimiter: <|startoftext|>
doc_to_text: "\u0645\u062A\u0646 \u0632\u06CC\u0631 \u062F\u0631 \u0686\u0647 \u0637\
      \u0628\u0642\u0647 \u0628\u0646\u062F\u06CC \u0645\u06CC\u062A\u0648\u0627\u0646\
      \u062F \u0642\u0631\u0627\u0631 \u0628\u06AF\u06CC\u0631\u062F\u061F\n\n\u0645\
      \u062A\u0646: {{question}} {{candidates[answer-1]}}\n\u0637\u0628\u0642\u0647\
      \ \u0628\u0646\u062F\u06CC: <|startoftext|>"
doc_to_target: "{% if category == 'math_and_logic' %}\n\u0631\
      \u06CC\u0627\u0636\u06CC \u0648 \u0645\u0646\u0637\u0642\n{% elif category ==\
      \ 'common_knowledge'%}\n\u0627\u0637\u0644\u0627\u0639\u0627\u062A \u0639\u0645\
      \u0648\u0645\u06CC\n{% else  %}\n\u0627\u062F\u0628\u06CC\u0627\u062A\n{% endif\
      \ %}"
training_split: train
validation_split: validation
test_split: test
metric_list:
  - metric: exact_match
    aggregation: mean
    higher_is_better: true